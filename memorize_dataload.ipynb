{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Neues Vokabular--2023-11-17', 'Neues Vokabular--2023-12-07', 'Neues Vokabular--2023-11-20', 'Neues Vokabular--2023-12-01', 'Neues Vokabular--2023-10-30', 'Neues Vokabular--2023-10-26', 'Neues Vokabular--2023-11-27', 'Neues Vokabular--2023-11-30', 'Neues Vokabular--2023-10-27', 'Neues Vokabular--2023-10-31', 'Neues Vokabular--2023-10-28', 'Neues Vokabular--2023-11-25', 'Neues Vokabular--2023-10-25', 'Neues Vokabular--2023-11-24', 'Neues Vokabular--2023-12-02', 'Neues Vokabular--2023-11-29_12h', 'Neues Vokabular--2023-12-04', 'Neues Vokabular--2023-12-08', 'Neues Vokabular--2023-11-29_11h', 'Neues Vokabular--2023-10-23', 'Neues Vokabular--2023-11-22'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Nicole data to the database\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to the folder\n",
    "folder_path = '/Users/damiano/Desktop/German/Nicole'\n",
    "file_pattern = \"Neues*.xlsx\"  # Pattern for files starting with \"Neues\"\n",
    "\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file = 'database.xlsx'\n",
    "\n",
    "# Load a new dataframe or the old dataframe\n",
    "load = \"OLD\" # \"NEW\" or \"OLD\" (THINK BEFORE CLICKING, IT MAY CANCEL THE CURRENT DATABASE!)\n",
    "if load == \"NEW\":\n",
    "    dataframes_dict = {}\n",
    "elif load == \"OLD\":\n",
    "    dataframes_dict = pd.read_excel(excel_file, sheet_name=None)\n",
    "    # Now dataframes_dict contains all sheets from the Excel file as DataFrames\n",
    "\n",
    "\n",
    "# Iterate over all files in the folder matching the pattern\n",
    "for file_path in glob.glob(os.path.join(folder_path, file_pattern)):\n",
    "    # Extract filename without extension\n",
    "    file_name = os.path.basename(file_path).split('.')[0]\n",
    "\n",
    "    # Check if the file name already exists in the dictionary\n",
    "    if file_name not in dataframes_dict:\n",
    "\n",
    "        # Load the Excel file\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "\n",
    "        # Get the number of sheets in the file\n",
    "        num_sheets = len(excel_file.sheet_names)\n",
    "\n",
    "        ### 1st sheet ###\n",
    "        # Load the 1st sheet of the excel file into a DataFrame (sheet 0)\n",
    "        df_1 = excel_file.parse(sheet_name=0)\n",
    "\n",
    "        # Rename the 1st and 2nd column\n",
    "        df_1.columns = ['German', 'English']\n",
    "\n",
    "        # Clean the DataFrame and create a copy\n",
    "        cleaned_df_1 = df_1.dropna(how='all').copy()\n",
    "\n",
    "        # Add weights column\n",
    "        cleaned_df_1['weights'] = 1\n",
    "\n",
    "        # Add notes column\n",
    "        cleaned_df_1['notes'] = \"\"\n",
    "\n",
    "        if num_sheets == 1:\n",
    "            cleaned_df = cleaned_df_1\n",
    "\n",
    "        elif:\n",
    "            ### 2nd sheet ###\n",
    "            # Load the 2nd sheet of the excel file into a DataFrame (sheet 1)\n",
    "            df_2 = excel_file.parse(sheet_name=1)\n",
    "\n",
    "            # Assuming the German word is always followed by its English translation and description\n",
    "            # Create two separate DataFrames for German and English rows\n",
    "            df_german = df_2.iloc[::2].reset_index(drop=True)  # German words on even rows\n",
    "            df_english = df_2.iloc[1::2].reset_index(drop=True)  # English translations on odd rows\n",
    "\n",
    "            # Combine the two DataFrames\n",
    "            combined_df = pd.concat([df_german, df_english], axis=1)\n",
    "\n",
    "            # Rename columns\n",
    "            combined_df.columns = ['German', 'English_Description']\n",
    "\n",
    "            # Split the English and Description columns\n",
    "            combined_df[['English', 'notes']] = combined_df['English_Description'].str.split(' - ', expand=True)\n",
    "\n",
    "            # Now drop the 'English_Description' column\n",
    "            combined_df.drop(columns=['English_Description'], inplace=True)\n",
    "\n",
    "            # Clean the DataFrame and create a copy\n",
    "            cleaned_df_2 = combined_df.dropna(how='all').copy()\n",
    "\n",
    "            # Add weights column\n",
    "            cleaned_df_2['weights'] = 1\n",
    "\n",
    "            # Reorder the columns\n",
    "            cleaned_df_2 = cleaned_df_2[['German', 'English', 'weights', 'notes']].copy()\n",
    "\n",
    "            ### Merge the two sheets\n",
    "            sheets = [cleaned_df_1, cleaned_df_2]\n",
    "            cleaned_df = pd.concat(sheets)\n",
    "\n",
    "        elif num_sheets == 3:\n",
    "            ### 3rd sheet ONLY ###\n",
    "            # Load the 3rd sheet of the excel file into a DataFrame (sheet 2)\n",
    "            df_3 = excel_file.parse(sheet_name=2)\n",
    "\n",
    "            # Assuming that the order of rows is always:\n",
    "            # 1. the German word \n",
    "            # 2. its English translation \n",
    "            # 3. its description in German\n",
    "            # Create 3 separate DataFrames\n",
    "            df_german = df_3.iloc[0::3].reset_index(drop=True)  # German words, on rows starting with 0 and in steps of 3\n",
    "            df_english = df_3.iloc[1::3].reset_index(drop=True)  # English translations, on rows starting with 1 and in steps of 3\n",
    "            df_description = df_3.iloc[2::3].reset_index(drop=True)  # Description, on rows starting with 2 and in steps of 3\n",
    "\n",
    "            # Combine the two DataFrames\n",
    "            combined_df = pd.concat([df_german, df_english, df_description], axis=1)\n",
    "\n",
    "            # Rename columns\n",
    "            combined_df.columns = ['German', 'English', 'notes']\n",
    "\n",
    "            # Clean the DataFrame and create a copy\n",
    "            cleaned_df_2 = combined_df.dropna(how='all').copy()\n",
    "\n",
    "            # Add weights column\n",
    "            cleaned_df_2['weights'] = 1\n",
    "\n",
    "            # Reorder the columns\n",
    "            cleaned_df_2 = cleaned_df_2[['German', 'English', 'weights', 'notes']].copy()\n",
    "\n",
    "            ### Merge the two sheets\n",
    "            sheets = [cleaned_df_1, cleaned_df_2]\n",
    "            cleaned_df = pd.concat(sheets)\n",
    "        \n",
    "        else:\n",
    "            # Display a message \n",
    "            print(\"\\n ### Unrecognized Data Structure\", f\"The file '{file_name}' \\\n",
    "                                has an unexpected number of sheets.\")\n",
    " \n",
    "            \n",
    "        # reset the index and drop the old index\n",
    "        cleaned_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        dataframes_dict[file_name] = cleaned_df\n",
    "\n",
    "# Now dataframes_dict contains all the loaded and cleaned DataFrames\n",
    "\n",
    "dataframes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save database in excel\n",
    "\n",
    "with pd.ExcelWriter('database.xlsx') as writer:\n",
    "    for key, df in dataframes_dict.items():\n",
    "        df.to_excel(writer, sheet_name=key, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/damiano/Desktop/German/Nicole/Vokabular Preply -- bis 2023-12-07.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Neues Vokabular--2023-11-17', 'Neues Vokabular--2023-12-07', 'Neues Vokabular--2023-11-20', 'Neues Vokabular--2023-12-01', 'Neues Vokabular--2023-10-30', 'Neues Vokabular--2023-10-26', 'Neues Vokabular--2023-11-27', 'Neues Vokabular--2023-11-30', 'Neues Vokabular--2023-10-27', 'Neues Vokabular--2023-10-31', 'Neues Vokabular--2023-10-28', 'Neues Vokabular--2023-11-25', 'Neues Vokabular--2023-10-25', 'Neues Vokabular--2023-11-24', 'Neues Vokabular--2023-12-02', 'Neues Vokabular--2023-11-29_12h', 'Neues Vokabular--2023-12-04', 'Neues Vokabular--2023-12-08', 'Neues Vokabular--2023-11-29_11h', 'Neues Vokabular--2023-10-23', 'Neues Vokabular--2023-11-22', 'Vok Preply_1', 'Vok Preply_2', 'Vok Preply_3', 'Vok Preply_4', 'Vok Preply_5', 'Vok Preply_6', 'Vok Preply_7', 'Vok Preply_8', 'Vok Preply_9', 'Vok Preply_10', 'Vok Preply_11', 'Vok Preply_12', 'Vok Preply_13', 'Vok Preply_14'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Preply vocabulary to the database\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to the folder\n",
    "folder_path = '/Users/damiano/Desktop/German/Nicole'\n",
    "file_pattern = \"Vokabular*.xlsx\"  # Pattern for files starting with \"Neues\"\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file = 'database.xlsx'\n",
    "\n",
    "# Read the database Excel file into a dictionary of DataFrames\n",
    "dataframes_dict = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "# Path to the folder\n",
    "file_path = glob.glob(os.path.join(folder_path, file_pattern))[0]\n",
    "print(file_path)\n",
    "# Extract filename without extension\n",
    "file_name = os.path.basename(file_path).split('.')[0]\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming the German word is always followed by its English translation and description\n",
    "# Create two separate DataFrames for German and English rows\n",
    "df_german = df.iloc[::2].reset_index(drop=True)  # German words on even rows\n",
    "df_english = df.iloc[1::2].reset_index(drop=True)  # English translations on odd rows\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([df_german, df_english], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "combined_df.columns = ['German', 'English_Description']\n",
    "\n",
    "# Split the English and Description columns\n",
    "combined_df[['English', 'notes']] = combined_df['English_Description'].str.split(' - ', expand=True)\n",
    "\n",
    "# Now drop the 'English_Description' column\n",
    "combined_df.drop(columns=['English_Description'], inplace=True)\n",
    "\n",
    "# Clean the DataFrame and create a copy\n",
    "cleaned_df = combined_df.dropna(how='all').copy()\n",
    "\n",
    "# Add weights column\n",
    "cleaned_df['weights'] = 1\n",
    "\n",
    "# Reorder the columns\n",
    "cleaned_df = cleaned_df[['German', 'English', 'weights', 'notes']].copy()\n",
    "\n",
    "# reset the index and drop the old index\n",
    "cleaned_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(0, len(cleaned_df), 25):\n",
    "    df_cut = cleaned_df.iloc[i:i + 25]\n",
    "    df_cut.reset_index(drop=True, inplace=True) \n",
    "    dataframes_dict[f'Vok Preply_{i // 25 + 1}'] = df_cut\n",
    "\n",
    "dataframes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
